---
id: d5d879r
status: closed
closed: 2026-01-04T16:50:47Z
blocked-by: []
created: 2026-01-04T15:13:43Z
type: feature
priority: 2
assignee: Calvin Alkan
---
# Add mtime-based cache for ListTickets

ListTickets opens and parses all ticket files on every call. At 100k tickets this takes ~400ms.

Add a gob-encoded cache file (.tickets/.cache) that stores parsed frontmatter with file mtimes. On subsequent runs, stat() each file and only re-parse files where mtime changed.

Expected performance:
- Cold (no cache): same as now (~400ms for 100k)
- Warm (no changes): ~10-20ms (just stat calls)
- Warm (1 file changed): ~15ms (stat all + parse 1)

## Design

### Cache file format

```go
// .tickets/.cache (gob-encoded)
type TicketCache struct {
    Entries map[string]CacheEntry // filename (without path) -> entry
}

type CacheEntry struct {
    Mtime   time.Time     // file mtime when parsed
    Summary TicketSummary // parsed frontmatter
}
```

### New file: cache.go

```go
const cacheFileName = ".cache"

func LoadCache(ticketDir string) (*TicketCache, error)
func SaveCache(ticketDir string, cache *TicketCache) error
```

### Changes to ticket.go

Add new `ListTicketsOptions` struct and modify signature:

```go
type ListTicketsOptions struct {
    NeedAll bool  // true if caller needs all tickets (e.g., has status filter)
    Limit   int   // max tickets to return (0 = no limit)
    Offset  int   // skip first N tickets
}

func ListTickets(ticketDir string, opts ListTicketsOptions) ([]TicketResult, error)
```

When `NeedAll` is false (no status filter), we can skip files:
- ReadDir returns sorted filenames
- Apply offset/limit to filenames directly  
- Only stat/cache-check/parse those files
- Skip remaining files entirely

When `NeedAll` is true (status filter used):
- Must check all files (via cache or parse)
- Apply offset/limit after filtering

### Changes to ls.go

Pass options based on whether `--status` flag is used:

```go
opts := ListTicketsOptions{
    NeedAll: statusFilter != "",  // need all if filtering by status
    Limit:   *limit,
    Offset:  *offset,
}
results, err := ListTickets(ticketDir, opts)
```

### Changes to ready.go, repair.go

Always pass `NeedAll: true` (they need all tickets).

### ListTickets implementation

Keep the existing parallel WaitGroup pattern. Key changes:

1. **Single loop:** Filter .md files, apply offset/limit, spawn goroutines - all in one pass
2. **Pre-allocate with upper bound:** Use `len(entries)` as capacity, slice at end
3. **Index-based writes:** Each goroutine writes to its index, no mutex needed for results
4. **Inside goroutines:** Add cache check before parsing

```go
func ListTickets(ticketDir string, opts ListTicketsOptions) ([]TicketResult, error) {
    cache, _ := LoadCache(ticketDir)  // ignore error, treat as empty
    cacheChanged := false
    var cacheMu sync.Mutex  // only protects cache writes
    
    entries, err := os.ReadDir(ticketDir)  // returns sorted by filename
    // ...
    
    results := make([]TicketResult, len(entries))  // upper bound
    var wg sync.WaitGroup
    mdCount := 0
    resultIdx := 0
    
    for _, entry := range entries {
        // Skip non-.md files (.cache, logs, etc)
        if !strings.HasSuffix(entry.Name(), ".md") {
            continue
        }
        
        // Skip for offset (when NeedAll=false)
        if !opts.NeedAll && mdCount < opts.Offset {
            mdCount++
            continue
        }
        
        // Stop at limit (when NeedAll=false)
        if !opts.NeedAll && opts.Limit > 0 && mdCount >= opts.Offset+opts.Limit {
            break
        }
        
        mdCount++
        idx := resultIdx  // capture index for goroutine
        resultIdx++
        path := filepath.Join(ticketDir, entry.Name())
        
        wg.Add(1)
        go func(i int, p string, e os.DirEntry) {
            defer wg.Done()
            
            info, _ := e.Info()  // stat() call
            mtime := info.ModTime()
            filename := e.Name()
            
            // Check cache first
            if cached, ok := cache.Entries[filename]; ok && cached.Mtime.Equal(mtime) {
                // Cache hit - no file open needed
                results[i] = TicketResult{Path: p, Summary: &cached.Summary}
                return
            }
            
            // Cache miss - parse file
            summary, parseErr := ParseTicketFrontmatter(p)
            results[i] = TicketResult{Path: p, Summary: &summary, Err: parseErr}
            
            // Update cache (needs mutex)
            cacheMu.Lock()
            cache.Entries[filename] = CacheEntry{Mtime: mtime, Summary: summary}
            cacheChanged = true
            cacheMu.Unlock()
        }(idx, path, entry)
    }
    
    wg.Wait()
    
    // Save cache if changed
    if cacheChanged {
        SaveCache(ticketDir, cache)
    }
    
    // Slice to actual count (results already in order - ReadDir returns sorted)
    return results[:resultIdx], nil
}
```

**What stays the same:**
- Parallel goroutines with WaitGroup
- ParseTicketFrontmatter for actual parsing
- Index-based writes (no sort needed - ReadDir returns sorted)

**What's new:**
- Single loop (no separate mdFiles slice)
- Pre-allocate with upper bound, slice at end
- Load/save cache
- Skip files inline when NeedAll=false (offset/limit)
- Cache check before parse in each goroutine
- Mutex only for cache updates (not for results)

**Why this works:** `stat()` is cheap (metadata only), `open()+read()` is expensive. On warm cache we skip all file opens.

### Callers (no changes needed)

- `ls.go` - calls ListTickets, unchanged
- `ready.go` - calls ListTickets, unchanged  
- `repair.go` - calls ListTickets, unchanged

### Write operations (no changes needed)

- `create.go` - writes new file, cache will see new file on next ListTickets
- `close.go`, `start.go`, `reopen.go` - update file, mtime changes, cache invalidates
- `block.go`, `unblock.go` - update file, mtime changes
- `repair.go` - updates files, mtime changes

Filesystem is source of truth. Cache just avoids re-parsing unchanged files.

### .gitignore

Add `.tickets/.cache` - cache is local, shouldn't be committed.

## Acceptance Criteria

### Functionality

- [ ] Cache stored in `.tickets/.cache` as gob-encoded file
- [ ] Cache hit when file mtime unchanged
- [ ] Cache miss and re-parse when file mtime changed
- [ ] New files parsed and added to cache
- [ ] Deleted files removed from cache
- [ ] Corrupted/missing cache file treated as empty (cold start)

### Correctness

- [ ] Read after write sees new data (write changes mtime, invalidates cache)
- [ ] `tk create` then `tk ls` shows new ticket
- [ ] `tk close <id>` then `tk ls` shows closed status
- [ ] Delete .md file manually, `tk ls` doesn't show it

### Performance

- [ ] Cold cache: similar to current (~400ms for 100k)
- [ ] Warm cache, no changes: <50ms for 100k
- [ ] Warm cache, 1 change: <50ms for 100k

## Testing & Benchmarking

### Setup test data

```bash
# Seed benchmark directories (1k, 10k, 50k, 100k tickets)
go run seed-bench.go

# Creates:
# /tmp/tk-bench/1000/.tickets/
# /tmp/tk-bench/10000/.tickets/
# /tmp/tk-bench/50000/.tickets/
# /tmp/tk-bench/100000/.tickets/
```

### Use existing benchmark files

- `bench_test.go` - Go benchmarks for `BenchmarkLs100k`, `BenchmarkReady100k`
- `seed-bench.go` - Seeds test directories with tickets

### Run benchmarks with hyperfine

```bash
# Before/after comparison
make build

# Cold cache (delete .cache first)
rm -f /tmp/tk-bench/100000/.tickets/.cache
hyperfine --warmup 1 './tk -C /tmp/tk-bench/100000 ls --limit=10'

# Warm cache (second run)
hyperfine --warmup 1 './tk -C /tmp/tk-bench/100000 ls --limit=10'

# Compare across sizes
hyperfine \
  './tk -C /tmp/tk-bench/1000 ls --limit=10' \
  './tk -C /tmp/tk-bench/10000 ls --limit=10' \
  './tk -C /tmp/tk-bench/50000 ls --limit=10' \
  './tk -C /tmp/tk-bench/100000 ls --limit=10'
```

### Profile with pprof

```bash
# Run benchmark with CPU profiling
go test -bench=BenchmarkLs100k -cpuprofile=cpu.prof -benchtime=5s

# Analyze
go tool pprof -top cpu.prof        # top functions
go tool pprof -top -cum cpu.prof   # by cumulative time
go tool pprof -web cpu.prof        # flamegraph (needs graphviz)
```

### Expected results

| Scenario | Before | After |
|----------|--------|-------|
| 100k cold | ~400ms | ~400ms |
| 100k warm | ~400ms | <50ms |
| 100k 1 file changed | ~400ms | <50ms |

### Edge cases

- [ ] Empty ticket directory works
- [ ] Missing cache file works (cold start)
- [ ] Corrupted cache file works (treat as cold start)
- [ ] Concurrent reads don't corrupt cache

### Tests

#### Cache tests
- [ ] Test cache hit (no file changes)
- [ ] Test cache miss (file modified)
- [ ] Test new file added
- [ ] Test file deleted
- [ ] Test corrupted cache recovery
- [ ] Test read-after-write consistency
- [ ] Test direct file modification outside tk (e.g., echo >> file.md) busts cache

#### Skip optimization tests (NeedAll=false)
- [ ] `ls --limit=10` only stats/opens 10 files (not 100k)
- [ ] `ls --offset=5 --limit=10` only stats/opens 10 files
- [ ] `ls --limit=10` returns correct (oldest) 10 tickets
- [ ] `ls --offset=5 --limit=10` skips first 5, returns next 10
- [ ] `ls --offset=99995 --limit=10` works at end of list

#### No-skip scenarios (NeedAll=true)  
- [ ] `ls --status=open --limit=10` checks all files
- [ ] `ls --status=closed` checks all files
- [ ] `ready` checks all files
- [ ] `repair --all` checks all files

#### Invariants
- [ ] Same results with/without cache (correctness)
- [ ] Same results with NeedAll=true vs false when no filter (correctness)
- [ ] Offset + limit at boundary conditions (offset >= total, limit > remaining)
